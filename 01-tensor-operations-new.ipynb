{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#-Array-operations-in-PyTorch\" data-toc-modified-id=\"-Array-operations-in-PyTorch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span> Array operations in PyTorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multiplication\" data-toc-modified-id=\"Multiplication-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Multiplication</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-1.\" data-toc-modified-id=\"Example-1.-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Example 1.</a></span></li><li><span><a href=\"#Example-2.\" data-toc-modified-id=\"Example-2.-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Example 2.</a></span></li><li><span><a href=\"#Example-3.\" data-toc-modified-id=\"Example-3.-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Example 3.</a></span></li></ul></li><li><span><a href=\"#Transpose\" data-toc-modified-id=\"Transpose-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Transpose</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-1.\" data-toc-modified-id=\"Example-1.-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Example 1.</a></span></li><li><span><a href=\"#Example-2.\" data-toc-modified-id=\"Example-2.-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Example 2.</a></span></li><li><span><a href=\"#Example-3.\" data-toc-modified-id=\"Example-3.-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Example 3.</a></span></li></ul></li><li><span><a href=\"#Gradient\" data-toc-modified-id=\"Gradient-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Gradient</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-1.\" data-toc-modified-id=\"Example-1.-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Example 1.</a></span></li><li><span><a href=\"#Example-2.\" data-toc-modified-id=\"Example-2.-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Example 2.</a></span></li><li><span><a href=\"#Example-3.\" data-toc-modified-id=\"Example-3.-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Example 3.</a></span></li></ul></li><li><span><a href=\"#Eigenvalues,-eigenvectors\" data-toc-modified-id=\"Eigenvalues,-eigenvectors-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Eigenvalues, eigenvectors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-1.\" data-toc-modified-id=\"Example-1.-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Example 1.</a></span></li><li><span><a href=\"#Example-2.\" data-toc-modified-id=\"Example-2.-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Example 2.</a></span></li><li><span><a href=\"#Example-3.\" data-toc-modified-id=\"Example-3.-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>Example 3.</a></span></li></ul></li><li><span><a href=\"#Least-square-norm\" data-toc-modified-id=\"Least-square-norm-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Least square norm</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Array operations in PyTorch</h1>\n",
    "<p class=\"author\">(Szabó Sándor, 27. May 2020)</p>\n",
    "\n",
    "<p class=\"abstract\">We will consider some common operations for matrices:</p>\n",
    "<p>\n",
    "<ul class=\"square\">\n",
    "    <li>multiplication</li>\n",
    "    <li>transpose</li>\n",
    "    <li>gradient</li>\n",
    "    <li>eigenvalues, eigenvectors</li>\n",
    "    <li>least square norm</li>\n",
    "</ul>\n",
    "</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Multiplication</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "<p class=\"normal\">\n",
    "    Since multiplication is <span style=\"font-style: italic;\">not</span> commutative, we need to take care of the order.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 1.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9140, -0.5622, -1.5553,  2.3507],\n",
       "        [-1.3446,  0.9200,  1.5791, -1.9014]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "A = torch.randn(2, 3)\n",
    "B = torch.randn(3, 4)\n",
    "torch.mm(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 2.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "<p class=\"normal\">However if you change the order you obtain</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [3 x 4], m2: [2 x 3] at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-9msmi1s9\\aten\\src\\TH/generic/THTensorMath.cpp:197",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-56583f172700>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example 2 - breaking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [3 x 4], m2: [2 x 3] at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-9msmi1s9\\aten\\src\\TH/generic/THTensorMath.cpp:197"
     ]
    }
   ],
   "source": [
    "# Example 2 - breaking\n",
    "torch.mm(B, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background remarks\">\n",
    "    <p class=\"normal\">\n",
    "    <span class=\"code\">torch.mm</span> does not broadcast. \n",
    "    For broadcasting matrix products, see <span class=\"code\">torch.matmul()</span>.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 3.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "<p class=\"normal\">If your keyboard has the character '@', then you can write </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9140, -0.5622, -1.5553,  2.3507],\n",
       "        [-1.3446,  0.9200,  1.5791, -1.9014]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3\n",
    "A @ B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transpose</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "<p class=\"normal\">When we transpose a matrix we transform rows to columns, and columns to rows.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 1.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.5627, -1.9438],\n",
       "        [ 0.9010,  0.0195],\n",
       "        [-0.6105,  1.0287]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 \n",
    "torch.t(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 2.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "<p class=\"normal\">Again, you should thoughtful, because $(AB)^T\\neq A^T B^T$, indeed</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8713, -5.5473, -0.1341],\n",
       "        [ 2.8685,  0.4661, -2.0915],\n",
       "        [ 1.6289,  2.5733,  1.4052]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "C = torch.randn(3, 3)\n",
    "D = torch.randn(3, 3)\n",
    "torch.t(C @ D) - (torch.t(C) @ torch.t(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "<p class=\"normal\">The correct result is $(AB)^T=B^T A^T$.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 3.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3\n",
    "torch.t(C @ D) - (torch.t(D) @ torch.t(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Gradient</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "    <p class=\"normal\">In machine learning we should minimize different type \n",
    "        of error function.</p>\n",
    "    <p class=\"normal\">\n",
    "    The derivative of a multivariable scalar valued function is a matrix, the so-called \n",
    "    <a href=\"https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant\">\n",
    "    Jacobi matrix</a>.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "<p class=\"normal\">If you want to calculate the derivative, you should give this option \n",
    "    in the definition of the tensor, using <span class=\"code\">requires_grad=True</span></p>\n",
    "<p class=\"normal\">In Example 1 we use the vector norm (in fact, the Frobenius norm, which gives the \n",
    "    Eucledian vector norm in case of vectors).</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 1.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: \n",
      " tensor([[ 1.8279,  3.2379,  0.1823],\n",
      "        [-0.6493, -0.2778, -0.6017],\n",
      "        [ 0.1859, -0.2227, -0.6932]], requires_grad=True)\n",
      "x: \n",
      " tensor([[ 1.1165],\n",
      "        [-0.4929],\n",
      "        [-0.2975]], requires_grad=True)\n",
      "b: \n",
      " tensor([[-0.1906],\n",
      "        [ 0.9892],\n",
      "        [-0.7800]], requires_grad=True)\n",
      "y: \n",
      " tensor(1.9980, grad_fn=<NormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "# Create tensors.\n",
    "A = torch.randn(3, 3, requires_grad=True)\n",
    "x = torch.randn(3, 1, requires_grad=True)\n",
    "b = torch.randn(3, 1, requires_grad=True)\n",
    "y = torch.norm(A @ x - b, p='fro')\n",
    "print(\"A: \\n\", A)\n",
    "print(\"x: \\n\", x)\n",
    "print(\"b: \\n\", b)\n",
    "print(\"y: \\n\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "    <p class=\"normal\">Now we calculate the derivatives $\\dfrac{\\partial y}{\\partial A}$, \n",
    "    $\\dfrac{\\partial y}{\\partial x}$, $\\dfrac{\\partial y}{\\partial b}$.</p>\n",
    "    <p class=\"normal\">To compute the derivatives, we call the <span class=\"code\">.backward \n",
    "        </span> method on our result $y$. </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∂y/∂A: \n",
      " tensor([[ 0.3249, -0.1434, -0.0865],\n",
      "        [-0.7814,  0.3449,  0.2082],\n",
      "        [ 0.7284, -0.3216, -0.1941]])\n",
      "∂y/∂x: \n",
      " tensor([[1.1075],\n",
      "        [0.9912],\n",
      "        [0.0218]])\n",
      "∂y/∂b: \n",
      " tensor([[-0.2910],\n",
      "        [ 0.6998],\n",
      "        [-0.6524]])\n"
     ]
    }
   ],
   "source": [
    "# Compute derivatives\n",
    "y.backward()\n",
    "\n",
    "# Display gradients\n",
    "print('∂y/∂A: \\n', A.grad)\n",
    "print('∂y/∂x: \\n', x.grad)\n",
    "print('∂y/∂b: \\n', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 2.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "    <p class=\"normal\">Instead of Frobenius norm we can choose any $1\\leq p<\\infty$ norm.\n",
    "    In the next example we choose $p=1$.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "∂w/∂A: \n",
      " tensor([[ 1.4414, -0.6363, -0.3840],\n",
      "        [-1.8979,  0.8379,  0.5056],\n",
      "        [ 1.8450, -0.8145, -0.4915]])\n",
      "∂w/∂x: \n",
      " tensor([[3.7706],\n",
      "        [4.2842],\n",
      "        [0.1126]])\n",
      "∂w/∂b: \n",
      " tensor([[-1.2910],\n",
      "        [ 1.6998],\n",
      "        [-1.6524]])\n"
     ]
    }
   ],
   "source": [
    "# Example 2 \n",
    "w = torch.norm(A @ x - b, p=1)\n",
    "              \n",
    "# Compute derivatives\n",
    "w.backward()\n",
    "\n",
    "# Display gradients\n",
    "print('∂w/∂A: \\n', A.grad)\n",
    "print('∂w/∂x: \\n', x.grad)\n",
    "print('∂w/∂b: \\n', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 3.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "    <p class=\"normal\">At this moment the infinity norm $p=\\infty$ does not work.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e4f599068e51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example 3 - breaking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Compute derivatives\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inf' is not defined"
     ]
    }
   ],
   "source": [
    "# Example 3 - breaking \n",
    "z = torch.norm(A @ x - b, p=inf)\n",
    "              \n",
    "# Compute derivatives\n",
    "z.backward()\n",
    "\n",
    "# Display gradients\n",
    "print('∂z/∂A: \\n', A.grad)\n",
    "print('∂z/∂x: \\n', x.grad)\n",
    "print('∂z/∂b: \\n', b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Eigenvalues, eigenvectors</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "    <p class=\"normal\">When we work on linear operators (matrices) many times is a must to \n",
    "    determine their eigenvalues and eigenvectors. \n",
    "    To do this, we use <span class=\"code\">torch.eig</span></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 1.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalue:  tensor([0.8710, 1.0656], grad_fn=<SelectBackward>)\n",
      "eigvector:  tensor([ 0.9046,  0.0000, -0.4537], grad_fn=<SelectBackward>)\n",
      "\n",
      "\n",
      "eigenvalue:  tensor([ 0.8710, -1.0656], grad_fn=<SelectBackward>)\n",
      "eigvector:  tensor([-0.2718,  0.3032,  0.3336], grad_fn=<SelectBackward>)\n",
      "\n",
      "\n",
      "eigenvalue:  tensor([-0.8852,  0.0000], grad_fn=<SelectBackward>)\n",
      "eigvector:  tensor([ 0.0798, -0.0975,  0.8264], grad_fn=<SelectBackward>)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 1 \n",
    "(eigvalues, eigvectors) = torch.eig(A, eigenvectors=True)\n",
    "for i in range(3):\n",
    "    print('eigenvalue: ', eigvalues[i])\n",
    "    print('eigvector: ', eigvectors[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"remarks\">\n",
    "    <p class=\"normal\">Since an eigenvalue can be complex, the first element in the tensor is \n",
    "    the real part and the second element is the imaginary part of it.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 2.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "    <p class=\"normal\">\n",
    "        Here is an example when the tensor has one eigenvalue with three different \n",
    "        eigenvectors.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalue:  tensor([2., 0.])\n",
      "eigenvector:  tensor([ 0.0000, -0.4472,  0.4082])\n",
      "\n",
      "\n",
      "eigenvalue:  tensor([2.0000, 0.0000])\n",
      "eigenvector:  tensor([ 0.0000,  0.8944, -0.8165])\n",
      "\n",
      "\n",
      "eigenvalue:  tensor([2.0000, 0.0000])\n",
      "eigenvector:  tensor([ 1.0000,  0.0000, -0.4082])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 2 \n",
    "C = torch.tensor([[0., -1., 0], [4., 4., 0], [2., 1., 2.]])\n",
    "\n",
    "(eigvalues, eigvectors) = torch.eig(C, eigenvectors=True)\n",
    "for i in range(3):\n",
    "    print('eigenvalue: ', eigvalues[i])\n",
    "    print('eigenvector: ', eigvectors[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Example 3.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"background\">\n",
    "    <p class=\"normal\">Only square matrices can have eigenvalues.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 1: A should be square at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-9msmi1s9\\aten\\src\\TH/generic/THTensorLapack.cpp:195",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-dfab705752e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0meigvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meigvectors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 1: A should be square at C:\\Users\\builder\\AppData\\Local\\Temp\\pip-req-build-9msmi1s9\\aten\\src\\TH/generic/THTensorLapack.cpp:195"
     ]
    }
   ],
   "source": [
    "# Example 3 \n",
    "D = torch.tensor([[0., -1., 0], [4., 4., 0]])\n",
    "\n",
    "(eigvalues, eigvectors) = torch.eig(D, eigenvectors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Least square norm</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
